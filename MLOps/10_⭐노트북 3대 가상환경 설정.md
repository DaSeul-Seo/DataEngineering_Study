- apt update
    - sudo apt-get update
- ssh 설치
    - sudo apt-get install openssh-server
- SHA Key 설정
    
    ```bash
    ssh-keygen -t rsa
    cd ~/.ssh
    cat id_rsa
    cat id_rsa.pub
    cat id_rsa.pub > authorized_keys
    chmod 600 ./authorized_keys
    ```        
        
- 방화벽 해제
    
    ```bash
    # 방확벽 죽이기 (부팅할 때부터 방화벽 데몬 정지)
    sudo systemctl disable ufw
    
    # 방화벽 서비스 끄기
    sudo service ufw stop
    
    # swap 끄기
    swapoff -a
    ```
    
- jdk 설치
    - hadoop은 JVM 위에서 돌아간다.
    
    ```bash
    # jdk 설치
    sudo apt install openjdk-8-jdk
    
    # 프로그램 위치 확인 
    whereis java
    
    # 실제 실행되는 프로그램 위치확인
    which java 
    ls -al /usr/bin | grep java
    /usr/lib/jvm/java-8-openjdk-amd64
    
    # 환경설정에 추가
    vim ~/.bashrc
    # 변수 추가
    export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
    # 다시 로딩
    source ~/.bashrc 
    # 변수 확인
    echo $JAVA_HOME
    ```
    
- hadoop 설치
    
    ```bash
    # 홈으로 이동
    cd ~
    # hadoop 설치
    wget https://dlcdn.apache.org/hadoop/common/hadoop-3.3.6/hadoop-3.3.6.tar.gz
    # 압축 풀기
    tar xvfz hadoop-3.3.6.tar.gz
    # 폴더 이름 변경 하기 
    mv ./hadoop-3.3.6  ./hadoop
    ```
    
    - 설정파일 복사
        - core-site.xml : 클러스터 내 네임노드에서 실행되는 하둡 데몬에 관한 설정
            
            ```bash
            <configuration>
            	<property>
            		<name>fs.defaultFS</name>
            		<value>hdfs://{호스트명}:{포트}</value>
            	</property>
            </configuration>
            ```
            
        - hdfs-site.xml : hadoop 파일 시스템에 관한 설정
            - namespace와 트랜잭션 로그를 저장할 네임노드와 데이터 노드의 저장경로를 지정하고, 데이터 복제 개수를 설정
            
            ```bash
            <configuration>
                <property>
                    <name>dfs.namenode.name.dir</name>
                    <value>file:///data/namenode</value>
                </property>
                <property>
                    <name>dfs.datanode.data.dir</name>
                    <value>file:///data/datanode</value>
                </property>
                <property>
                    <name>dfs.namenode.checkpoint.dir</name>
                    <value>file:///data/namesecondary</value>
                </property>
                <property>
                    <name>dfs.replication</name>
                    <value>3</value>
                </property>
            </configuration>
            ```
            
        - mapred-site.xml : 맵리듀스에 관한 설정
            - 기본 맵리듀스 프레임워크로 yarn을 설정
            
            ```bash
            <configuration>
                <property>
                    <name>mapreduce.framework.name</name>
                    <value>yarn</value>
                </property>
            </configuration>
            ```
            
        - yarn-site.xml : yarn 설정파일 - Resource Manager에 관한 설정
            - 리소스 매니저 Web-ui 주소, 노드 매니저에서 중간 단계 파일 및 로그를 저장할 경로 정의
            
            ```bash
            <configuration>
                <property>
                    <name>yarn.nodemanager.local-dirs</name>
                    <value>file:///data/yarn/local</value>
                </property>
                <property>
                    <name>yarn.nodemanager.log-dirs</name>
                    <value>file:///data/yarn/logs</value>
                </property>
                <property>
                    <name>yarn.resourcemanager.hostname</name>
                    <value>hmng</value>
                </property>
            </configuration>
            ```
            
        - workers
- bashrc에 hadoop 설정
    
    ```bash
    export HADOOP_HOME=/home/hadoop/hadoop
    export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
    export HADOOP_INSTALL=$HADOOP_HOME
    export HADOOP_MAPRED_HOME=$HADOOP_HOME
    export HADOOP_COMMON_HOME=$HADOOP_HOME
    export HADOOP_HDFS_HOME=$HADOOP_HOME
    export HADOOP_YARN_HOME=$HADOOP_HOME
    export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
    export HADOOP_OPTS="-Djava.library.path=$HADOOP_HOME/lib/native"
    export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin:$HIVE_HOME/bin
    ```
    
    - source ~/.bashrc
- hadoop 실행
    - HDFS → YARN → MR-History Server
    - namenode : start-dfs.sh
    - secondnode : start-yarn.sh
    - namenode : mr-jobhistory-demon.sh start historyserver
- hadoop 종료
    - YARN → MR-History Server → HDFS
    - secondnode : stop-yarn.sh
    - namenode : mr-jobhistory-demon.sh stop historyserver
    - namenode : stop-dfs.sh
- hadoop 실행 시 alias 사용하기
    - vi ~/.bashrc
    
    ```bash
    alias start-dfs="ssh namenode start-dfs.sh"
    alias start-yarn="ssh secondnode start-yarn.sh"
    alias stop-dfs="ssh namenode stop-dfs.sh"
    alias stop-yarn="ssh secondnode stop-yarn.sh"
    alias start-mr="ssh namenode mr-jobhistory-daemon.sh start historyserver"
    alias stop-mr="ssh namenode mr-jobhistory-daemon.sh stop historyserver"
    ```
    
    - source ~/.bashrc : 적용

<aside>
💡 Reference

</aside>

- 우분투 노트북 덮개 닫아도 대기모드에 진입하지 않게 설정하기
    - https://dontdiethere.tistory.com/27
- hadoop 설정파일
    - https://sparkdia.tistory.com/8