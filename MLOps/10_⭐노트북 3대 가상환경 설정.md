- apt update
    - sudo apt-get update
- ssh ì„¤ì¹˜
    - sudo apt-get install openssh-server
- SHA Key ì„¤ì •
    
    ```bash
    ssh-keygen -t rsa
    cd ~/.ssh
    cat id_rsa
    cat id_rsa.pub
    cat id_rsa.pub > authorized_keys
    chmod 600 ./authorized_keys
    ```        
        
- ë°©í™”ë²½ í•´ì œ
    
    ```bash
    # ë°©í™•ë²½ ì£½ì´ê¸° (ë¶€íŒ…í•  ë•Œë¶€í„° ë°©í™”ë²½ ë°ëª¬ ì •ì§€)
    sudo systemctl disable ufw
    
    # ë°©í™”ë²½ ì„œë¹„ìŠ¤ ë„ê¸°
    sudo service ufw stop
    
    # swap ë„ê¸°
    swapoff -a
    ```
    
- jdk ì„¤ì¹˜
    - hadoopì€ JVM ìœ„ì—ì„œ ëŒì•„ê°„ë‹¤.
    
    ```bash
    # jdk ì„¤ì¹˜
    sudo apt install openjdk-8-jdk
    
    # í”„ë¡œê·¸ë¨ ìœ„ì¹˜ í™•ì¸ 
    whereis java
    
    # ì‹¤ì œ ì‹¤í–‰ë˜ëŠ” í”„ë¡œê·¸ë¨ ìœ„ì¹˜í™•ì¸
    which java 
    ls -al /usr/bin | grep java
    /usr/lib/jvm/java-8-openjdk-amd64
    
    # í™˜ê²½ì„¤ì •ì— ì¶”ê°€
    vim ~/.bashrc
    # ë³€ìˆ˜ ì¶”ê°€
    export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
    # ë‹¤ì‹œ ë¡œë”©
    source ~/.bashrc 
    # ë³€ìˆ˜ í™•ì¸
    echo $JAVA_HOME
    ```
    
- hadoop ì„¤ì¹˜
    
    ```bash
    # í™ˆìœ¼ë¡œ ì´ë™
    cd ~
    # hadoop ì„¤ì¹˜
    wget https://dlcdn.apache.org/hadoop/common/hadoop-3.3.6/hadoop-3.3.6.tar.gz
    # ì••ì¶• í’€ê¸°
    tar xvfz hadoop-3.3.6.tar.gz
    # í´ë” ì´ë¦„ ë³€ê²½ í•˜ê¸° 
    mv ./hadoop-3.3.6  ./hadoop
    ```
    
    - ì„¤ì •íŒŒì¼ ë³µì‚¬
        - core-site.xml : í´ëŸ¬ìŠ¤í„° ë‚´ ë„¤ì„ë…¸ë“œì—ì„œ ì‹¤í–‰ë˜ëŠ” í•˜ë‘¡ ë°ëª¬ì— ê´€í•œ ì„¤ì •
            
            ```bash
            <configuration>
            	<property>
            		<name>fs.defaultFS</name>
            		<value>hdfs://{í˜¸ìŠ¤íŠ¸ëª…}:{í¬íŠ¸}</value>
            	</property>
            </configuration>
            ```
            
        - hdfs-site.xml : hadoop íŒŒì¼ ì‹œìŠ¤í…œì— ê´€í•œ ì„¤ì •
            - namespaceì™€ íŠ¸ëœì­ì…˜ ë¡œê·¸ë¥¼ ì €ì¥í•  ë„¤ì„ë…¸ë“œì™€ ë°ì´í„° ë…¸ë“œì˜ ì €ì¥ê²½ë¡œë¥¼ ì§€ì •í•˜ê³ , ë°ì´í„° ë³µì œ ê°œìˆ˜ë¥¼ ì„¤ì •
            
            ```bash
            <configuration>
                <property>
                    <name>dfs.namenode.name.dir</name>
                    <value>file:///data/namenode</value>
                </property>
                <property>
                    <name>dfs.datanode.data.dir</name>
                    <value>file:///data/datanode</value>
                </property>
                <property>
                    <name>dfs.namenode.checkpoint.dir</name>
                    <value>file:///data/namesecondary</value>
                </property>
                <property>
                    <name>dfs.replication</name>
                    <value>3</value>
                </property>
            </configuration>
            ```
            
        - mapred-site.xml : ë§µë¦¬ë“€ìŠ¤ì— ê´€í•œ ì„¤ì •
            - ê¸°ë³¸ ë§µë¦¬ë“€ìŠ¤ í”„ë ˆì„ì›Œí¬ë¡œ yarnì„ ì„¤ì •
            
            ```bash
            <configuration>
                <property>
                    <name>mapreduce.framework.name</name>
                    <value>yarn</value>
                </property>
            </configuration>
            ```
            
        - yarn-site.xml : yarn ì„¤ì •íŒŒì¼ - Resource Managerì— ê´€í•œ ì„¤ì •
            - ë¦¬ì†ŒìŠ¤ ë§¤ë‹ˆì € Web-ui ì£¼ì†Œ, ë…¸ë“œ ë§¤ë‹ˆì €ì—ì„œ ì¤‘ê°„ ë‹¨ê³„ íŒŒì¼ ë° ë¡œê·¸ë¥¼ ì €ì¥í•  ê²½ë¡œ ì •ì˜
            
            ```bash
            <configuration>
                <property>
                    <name>yarn.nodemanager.local-dirs</name>
                    <value>file:///data/yarn/local</value>
                </property>
                <property>
                    <name>yarn.nodemanager.log-dirs</name>
                    <value>file:///data/yarn/logs</value>
                </property>
                <property>
                    <name>yarn.resourcemanager.hostname</name>
                    <value>hmng</value>
                </property>
            </configuration>
            ```
            
        - workers
- bashrcì— hadoop ì„¤ì •
    
    ```bash
    export HADOOP_HOME=/home/hadoop/hadoop
    export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
    export HADOOP_INSTALL=$HADOOP_HOME
    export HADOOP_MAPRED_HOME=$HADOOP_HOME
    export HADOOP_COMMON_HOME=$HADOOP_HOME
    export HADOOP_HDFS_HOME=$HADOOP_HOME
    export HADOOP_YARN_HOME=$HADOOP_HOME
    export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
    export HADOOP_OPTS="-Djava.library.path=$HADOOP_HOME/lib/native"
    export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin:$HIVE_HOME/bin
    ```
    
    - source ~/.bashrc
- hadoop ì‹¤í–‰
    - HDFS â†’ YARN â†’ MR-History Server
    - namenode : start-dfs.sh
    - secondnode : start-yarn.sh
    - namenode : mr-jobhistory-demon.sh start historyserver
- hadoop ì¢…ë£Œ
    - YARN â†’ MR-History Server â†’ HDFS
    - secondnode : stop-yarn.sh
    - namenode : mr-jobhistory-demon.sh stop historyserver
    - namenode : stop-dfs.sh
- hadoop ì‹¤í–‰ ì‹œ alias ì‚¬ìš©í•˜ê¸°
    - vi ~/.bashrc
    
    ```bash
    alias start-dfs="ssh namenode start-dfs.sh"
    alias start-yarn="ssh secondnode start-yarn.sh"
    alias stop-dfs="ssh namenode stop-dfs.sh"
    alias stop-yarn="ssh secondnode stop-yarn.sh"
    alias start-mr="ssh namenode mr-jobhistory-daemon.sh start historyserver"
    alias stop-mr="ssh namenode mr-jobhistory-daemon.sh stop historyserver"
    ```
    
    - source ~/.bashrc : ì ìš©
</br>

### ğŸ’¡ Reference

- ìš°ë¶„íˆ¬ ë…¸íŠ¸ë¶ ë®ê°œ ë‹«ì•„ë„ ëŒ€ê¸°ëª¨ë“œì— ì§„ì…í•˜ì§€ ì•Šê²Œ ì„¤ì •í•˜ê¸°
    - https://dontdiethere.tistory.com/27
- hadoop ì„¤ì •íŒŒì¼
    - https://sparkdia.tistory.com/8