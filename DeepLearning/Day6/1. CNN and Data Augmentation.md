### torchvision Module

- torchvision.datasets
    - dataset 관련
- torchvision.models
    - 학습 모델 관련
- torchvision.transforms
    - 이미지 전처리 관련
- torch.utils.data.DataLoader

⭐

```python
import os, random
import numpy as np
import pandas as pd

# SEED = 42

# 모든 seed를 고정
def reset_seeds(seed=42):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)    # 파이썬 환경변수 시드 고정
    np.random.seed(seed)
    torch.manual_seed(seed) # cpu 연산 무작위 고정
    torch.cuda.manual_seed(seed) # gpu 연산 무작위 고정
    torch.backends.cudnn.deterministic = True  # cuda 라이브러리에서 Deterministic(결정론적)으로 예측하기 (예측에 대한 불확실성 제거 )

reset_seeds()
# 셀 단위로 SEED를 고정해야 한다.
```

### CNN 구조

![1](https://github.com/DaSeul-Seo/DataEngineering_Study/assets/67898022/c58f9154-b16e-495a-9707-28a2a2357e18)

1. Convolution Layer
    1. 한 장의 이미지를 n개의 이미지로 불린다.
    2. 각각의 이미지에 대한 특징들을 한 장 한 장 만든다.
        1. 사람들의 뉴런들은 수평만 인지, 대각선만 인지, 각각의 특징들을 기억한다는 설이 있다.
        2. Convolution Layer도 각 특징들을 이용해 특성을 뽑을 수 있다. (원본 이미지 크기)
    3. feature를 뽑는다. (ML에서 feature를 뽑는 역활과 비슷)
    4. 이미지 크기 변화 X, 이미지 장수 증가
2. Max Pooling Layer
    1. 하나하나의 이미지의 크기를 줄인다.
    2. 각각의 특성들을 뽑으면 정보들이 일부만 들어가 있기에 (원본 이미지 크기) 모델이 학습하기에는 비효율적이다.
    3. 학습을 효율적으로 하기 위해 이미지의 크기를 압축한다. (특성만 존재하게)
    4. 이미지의 장수 고정, 이미지 크기 변화 O
3. Convolution Layer, Max Pooling Layer 반복
    1. 각각 특성도 증가, 압축도 증가
4. Flatten Layer
    1. 학습
- 장점
    - Convolution Layer, Max Pooling Layer 이미지 특성을 추출
    - 연산량이 적다

### CNN 코드

1. Convolution Layer
    1. nn.Conv2d(in_channels, out_channels, kernel_size)
    2. (1, 2)stride = 수에 따라 듬성듬성 움직여 데이터 추출
    3. padding = 가장자리는 1번밖에 학습이 안되었기에 관심 영역이 가장자리에 있으면 추출하기가 어렵다. 그래서 padding(외부)을 주어서 학습을 제대로 할 수 있게 한다.
- Import Module

```python
# Import PyTorch
import torch
from torch import nn

from torch.utils.data import DataLoader

# Import torchvision
import torchvision
from torchvision import datasets, transforms
from torchvision.transforms import ToTensor

# Import matplotlib for visualization
import matplotlib.pyplot as plt

# Import tqdm for progress bar
from tqdm.auto import tqdm

# Check versions
# Note: your PyTorch version shouldn't be lower than 1.10.0 and torchvision version shouldn't be lower than 0.11
print(f"PyTorch version: {torch.__version__}\ntorchvision version: {torchvision.__version__}")

# 학습에 사용할 CPU나 GPU 장치를 얻습니다.
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f'device: {device}')
```

```python
!pip install torchinfo
import torchinfo
```

```python
import os, random
import numpy as np
import pandas as pd

# SEED = 42

def reset_seeds(seed=42):
    # 파이썬
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)    # 파이썬 환경변수 시드 고정
    # numpy & pandas -> 머신러닝
    np.random.seed(seed)
    # pytorch -> 딥러닝
    torch.manual_seed(seed) # cpu 연산 무작위 고정
    torch.cuda.manual_seed(seed) # gpu 연산 무작위 고정
    torch.backends.cudnn.deterministic = True  # cuda 라이브러리에서 Deterministic(결정론적)으로 예측하기 (예측에 대한 불확실성 제거 )

reset_seeds()
```

- 사용 함수 정의
    - 모델 평가
        
        ```python
        def eval_model(
            model: torch.nn.Module, # 딥러닝 모델
            data_loader: torch.utils.data.DataLoader, # 데이터 로더(배치)
            loss_fn: torch.nn.Module, # 로스함수
            accuracy_fn, # 평가함수
            device: torch.device = device # 디바이스(cpu, gpu)
        ):
        
            loss, acc = 0, 0 # test loss / test acc
            model.eval() # 평가 모드 전화
            with torch.inference_mode(): # 모델의 파라미터를 고정!!!!
                # 테스트 데이터 로드를 통해서
                # 배치 단위로 features, targets 뽑아낸다...
                # X -> 배치 단위로 모인 features들....
                # y -> 배치 단위로 모인 targets....
                for X, y in data_loader:
                    # 모델이 적용된 device에 feature, target 적용....
                    X, y = X.to(device), y.to(device)
                    # 모델이 feature를 이용하여 pred(예측)....
                    y_pred = model(X)
                    # y_pred(예측)과 y(실제)의 차이(loss) 구하자....
                    # loss_fn(y_pred, y) -> 전체 loss가 아닌, batch loss이다....
                    # loss += loss_fn(y_pred, y)
                    # -> 전체 데이터(epoch)의 loss ??
                    # -> batch loss들의 합이다....
                    loss += loss_fn(y_pred, y)
                    # 정확도를 계산하자....
                    acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))
        
                # Scale loss and acc
                # loss /= len(data_loader)
                # -> 전체 batch loss 합 / batch의 수
                # -> batch 평균의 loss 값이 -> epoch loss 값 정의할 수 있다.!!!!
                loss /= len(data_loader)
                acc /= len(data_loader)
            return {"model_name": model.__class__.__name__, # only works when model was created with a class
                    "model_loss": loss.item(),
                    "model_acc": acc}
        ```
        
    - 평가 점수 계산
        
        ```python
        # Calculate accuracy (a classification metric)
        def accuracy_fn(y_true, y_pred):
            """Calculates accuracy between truth labels and predictions.
        
            Args:
                y_true (torch.Tensor): Truth labels for predictions.
                y_pred (torch.Tensor): Predictions to be compared to predictions.
        
            Returns:
                [torch.float]: Accuracy value between y_true and y_pred, e.g. 78.45
            """
            correct = torch.eq(y_true, y_pred).sum().item()
            acc = (correct / len(y_pred)) * 100
            return acc
        ```
        
    - 소요시간
        
        ```python
        def print_train_time(start: float, end: float, device: torch.device = None):
            """Prints difference between start and end time.
        
            Args:
                start (float): Start time of computation (preferred in timeit format).
                end (float): End time of computation.
                device ([type], optional): Device that compute is running on. Defaults to None.
        
            Returns:
                float: time between start and end in seconds (higher is longer).
            """
            total_time = end - start
            print(f"Train time on {device}: {total_time:.3f} seconds")
            return total_time
        ```
        
    - Train Loop
        
        ```python
        # 1. 모델 학습
        # 2. 학습 결과에 loss 값
        # 3. loss값에 따라 역전파...
        def train_step(model: torch.nn.Module,
                        data_loader: torch.utils.data.DataLoader,
                        loss_fn: torch.nn.Module,
                        optimizer: torch.optim.Optimizer,
                        accuracy_fn,
                        device: torch.device = device):
            # 초기값
            model.to(device).train()
            train_loss, train_acc = 0, 0
        
            # batch 단위로 학습 시작!!!!
            # -> batch: 몇번째 학습을 진행하는지의 숫자 ...
            # -> X: features (batch, color, height, width)
            # -> y: target (batch)
            for batch, (X, y) in enumerate(data_loader):
                # 모델과 같은 device(cpu or gpu) 적용!!
                X, y = X.to(device), y.to(device)
        
                # 1. 모델 학습
                # 1. Forward pass
                y_pred = model(X)
        
                # 2. 학습 결과에 loss 값
                # 2. Calculate loss
                # loss ??? -> batch 단위의 실제값에서 예측값을 뺀 차이....
                loss = loss_fn(y_pred, y)
                train_loss += loss # 전체 loss를 계산하기 위해 batch 단위 loss를 합하기..
                train_acc += accuracy_fn(y_true=y,
                                        y_pred=y_pred.argmax(dim=1)) # y_pred(batch, pred)
        
                # 3. loss값에 따라 역전파...
                # 3. Optimizer zero grad
                optimizer.zero_grad()
        
                # 4. Loss backward
                loss.backward()
        
                # 5. Optimizer step
                optimizer.step()
        
            # train_loss -> batch 단위의 loss의 합
            # len(data_loader) -> 전체 데이터를 batch 단위로 나눈값...
            # 따라서 `train_loss /= len(data_loader)`는
            # batch 단위의 loss 평균값 -> 이것을 epoch 단위의 loss로 정의 !!!
            train_loss /= len(data_loader) # train_loss = train_loss / len(data_loader)
            train_acc /= len(data_loader)
            print(f"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%")
        
            return train_loss, train_acc
        ```
        
    - Test Loop
        
        ```python
        def test_step(data_loader: torch.utils.data.DataLoader,
                        model: torch.nn.Module,
                        loss_fn: torch.nn.Module,
                        accuracy_fn,
                        device: torch.device = device):
            # 초기화
            test_loss, test_acc = 0, 0
            model.eval() # put model in eval mode
        
            # 모델 파라미터를 고정하는 역할!!!!
            with torch.inference_mode():
                for X, y in data_loader:
                    # Send data to GPU
                    X, y = X.to(device), y.to(device)
        
                    # 예측한다..
                    # 1. Forward pass
                    test_pred = model(X)
        
                    # 예측값을 평가한다!!!
                    # 2. Calculate loss and accuracy
                    test_loss += loss_fn(test_pred, y)
                    test_acc += accuracy_fn(y_true=y,
                        y_pred=test_pred.argmax(dim=1) # Go from logits -> pred labels
                    )
        
                # Adjust metrics and print out
                test_loss /= len(data_loader)
                test_acc /= len(data_loader)
                print(f"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\n")
        
            return test_loss, test_acc
        ```
        
- Dataset

```python
# transforms -> 이미지 전처리를 해주는 모듈.....
# transforms.ToTensor() -> python 숫자를 torch의 tensor 형변환....
# transforms.Normalize()
# -> 데이터를 정규화 했다....
# -> 3차원 컬리이면, 2D 메트릭스 차원이기...
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])
```

```python
# pytorch의 dataset class 만들다..!!!!
train_set = torchvision.datasets.CIFAR10(
    root='./data',        # 데이터 저장 위치
    train=True,           # True: train set, False: test set
    download=True,       # 다운로드 여부, (이미 다운받았으면 False로 지정)
    transform=transform   # 데이터 선처리 작업
)

test_set = torchvision.datasets.CIFAR10(
    root='./data',
    train=False,
    download=True,
    transform=transform
)
```

```python
import requests
import zipfile
from pathlib import Path

# Setup path to data folder
data_path = Path("data/")
image_path = data_path / "pizza_steak_sushi" # data/pizza_steak_sushi

# If the image folder doesn't exist, download it and prepare it...
if image_path.is_dir():
    print(f"{image_path} directory exists.")
else:
    print(f"Did not find {image_path} directory, creating one...")
    image_path.mkdir(parents=True, exist_ok=True)

    # Download pizza, steak, sushi data
    with open(data_path / "pizza_steak_sushi.zip", "wb") as f:
        request = requests.get("https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip")
        print("Downloading pizza, steak, sushi data...")
        f.write(request.content)

    # Unzip pizza, steak, sushi data
    with zipfile.ZipFile(data_path / "pizza_steak_sushi.zip", "r") as zip_ref:
        print("Unzipping pizza, steak, sushi data...")
        zip_ref.extractall(image_path)
```

```python
import os

def walk_through_dir(dir_path):
  for dirpath, dirnames, filenames in os.walk(dir_path):
    print(f"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.")
```

```python
# Setup train and testing paths
train_dir = image_path / "train"
test_dir = image_path / "test"
```

```python
from torchvision import datasets

train_data = datasets.ImageFolder(root=train_dir, transform=simple_transform)
test_data = datasets.ImageFolder(root=test_dir, transform=simple_transform)
```

- DataLoader

```python
import os
from torch.utils.data import DataLoader

BATCH_SIZE = 32
NUM_WORKERS = os.cpu_count()
print(f"Creating DataLoader's with batch size {BATCH_SIZE} and {NUM_WORKERS} workers.")

train_dataloader = DataLoader(train_data, 
                              batch_size=BATCH_SIZE,
                              shuffle=True, # shuffle
                              num_workers=NUM_WORKERS)

test_dataloader = DataLoader(test_data,
                             batch_size=BATCH_SIZE,
                             shuffle=False,
                             num_workers=NUM_WORKERS)

train_dataloader, test_dataloader
```

- Model

```python
# 딥러닝 모델을 만들자!!!
# 1. nn.Module을 상속 받자!!!
# 2. __init__(생성함수)를 만들자...
  # -> 다른 필수 함수를 구현하기 위한 변수를 생성하는 함수...
# 3. forward(학습을 하는 함수)를 만들자...
  # -> 딥러닝 모델의 알고리즘에 맞춰서 코딩을 하자...
  # -> CNN -> Conv2D + Pooling + Linear

class CNNModelV1(nn.Module): # 1. nn.Module을 상속 받자!!!
    # 2. __init__(생성함수)를 만들자...
    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):
        # -> 다른 필수 함수를 구현하기 위한 변수를 생성하는 함수...
        super().__init__()
        # block_1 -> nn.Conv2d, nn.ReLU, nn.Conv2d, nn.ReLU, nn.MaxPool2d
        # -> nn.Conv2d * 2 + nn.MaxPool2d * 1
        self.block_1 = nn.Sequential(
            nn.Conv2d(in_channels=input_shape, # input_shape=3
	                    out_channels=hidden_units,
	                    kernel_size=3,
	                    stride=1,
	                    padding=1),
            nn.ReLU(),
            nn.Conv2d(in_channels=hidden_units,
	                    out_channels=hidden_units,
	                    kernel_size=3,
	                    stride=1,
	                    padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2,
                         stride=2)
        )
        # block_2 -> nn.Conv2d, nn.ReLU, nn.Conv2d, nn.ReLU, nn.MaxPool2d
        # -> nn.Conv2d * 2 + nn.MaxPool2d * 1
        self.block_2 = nn.Sequential(
            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2)
        )
        # classifier -> nn.Flatten, nn.Linear
        self.classifier = nn.Sequential(
            # block_2.shape -> 1D변경...  (batch(=32), hidden_units, 16, 16)
            # -> [32, 10, 16, 16]
            nn.Flatten(),
            nn.Linear(in_features=hidden_units*16*16, # in_features = (batch(=32), hidden_units*16*16)
                      out_features=hidden_units*16*16),
            nn.ReLU(),
            nn.Linear(in_features=hidden_units*16*16, # in_features = (batch(=32), hidden_units*16*16)
                      out_features=output_shape) # output_shape = len(target)
        )

    def forward(self, x: torch.Tensor): # (batch(=32), color(=3), height(=64), width(=64))
        x1 = self.block_1(x)
        x2 = self.block_2(x1)
        x3 = self.classifier(x2)
        return x3
```

```python
cnn_model = CNNModelV1(input_shape=3,
									     hidden_units=10,
									     output_shape=len(train_data.classes)).to(device)

cnn_model
```

```python
# cnn model
torchinfo.summary(cnn_model,(32, 3, 64, 64), col_names=["kernel_size", "input_size", "output_size", "num_params"])
```

- Training

```python
# Setup loss and optimizer
loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(params=cnn_model.parameters(),
                            lr=0.1)
```

```python
SEED = 42
reset_seeds()

# Measure time
from timeit import default_timer as timer
train_time_start_model_2 = timer()

# Train and test model
epochs = 30
eopch_list = []
train_loss_list = []
test_loss_list = []
train_acc_list = []
test_acc_list = []

for epoch in tqdm(range(epochs)):
    print(f"Epoch: {epoch}\n---------")
    eopch_list.append(epoch)
    train_loss, train_acc = train_step(data_loader=train_dataloader,
															         model=cnn_model,
															         loss_fn=loss_fn,
															         optimizer=optimizer,
															         accuracy_fn=accuracy_fn,
															         device=device)
    train_loss_list.append(train_loss.detach().numpy())
    train_acc_list.append(train_acc)

    test_loss, test_acc = test_step(data_loader=test_dataloader,
														        model=cnn_model,
														        loss_fn=loss_fn,
														        accuracy_fn=accuracy_fn,
														        device=device)
    test_loss_list.append(test_loss.detach().numpy())
    test_acc_list.append(test_acc)

train_time_end_model_2 = timer()
total_train_time_cnn_model = print_train_time(start=train_time_start_model_2,
                                              end=train_time_end_model_2,
                                              device=device)
```

- loss 그래프

```python
# Plot the loss curves
plt.plot(eopch_list, train_loss_list, label="Train loss")
plt.plot(eopch_list, test_loss_list, label="Test loss")
plt.title("Training and test loss curves")
plt.ylabel("Loss")
plt.xlabel("Epochs")
plt.legend();
```

- Confusion Matrix

```python
from tqdm.auto import tqdm

y_preds = []
cnn_model.eval()
with torch.inference_mode():
	# test 데이터 하나씩 가져오기 (feature, target)
  for X, y in tqdm(test_dataloader, desc = "Making predictions"):
		# 모델과 동일한 환경 세팅
    X, y = X.to(device), y.to(device)
		# 예측
    y_logit = cnn_model(X)
		# 예측값을 확률값으로 나타낸 후 최대값의 라벨 반환
    y_pred = torch.softmax(y_logit, dim = 1).argmax(dim = 1)
		# 라벨 리스트에 값 저장
    y_preds.append(y_pred.cpu())
  y_pred_tensor = torch.cat(y_preds)
```

```python
try:
  import torchmetrics, mlxtend
  print(f"mlxtend version: {mlxtend.__version__}")
  assert int(mlxtend.__version__.split(".")[1]) >= 19
except:
  !pip install -q torchmetrics -U mlxtend
  import torchmetrics, mlxtend
  print(f"mlxtend version: {mlxtend.__version__}")
```

```python
from torchmetrics import ConfusionMatrix
from mlxtend.plotting import plot_confusion_matrix

confmat = ConfusionMatrix(num_classes = len(train_data.classes), task = "multiclass")
confmat_tensor = confmat(preds = y_pred_tensor,
                         target = torch.tensor(test_data.targets))

fig, ax = plot_confusion_matrix(conf_mat = confmat_tensor.numpy(),
                                class_names = train_data.classes,
                                figsize = (10, 7))
```

<aside>
💡 Reference

</aside>

- https://pytorch.org/vision/stable/index.html
- CNN
    - https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md
    - https://poloclub.github.io/cnn-explainer/
