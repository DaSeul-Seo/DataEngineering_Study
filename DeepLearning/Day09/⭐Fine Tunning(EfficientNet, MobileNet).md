### â­ Fine Tunning (ë¯¸ì„¸ ì¡°ì •))

- Pre Training (ì‚¬ì „í•™ìŠµ)
    - Datasetì„ ê¸°ë°˜ìœ¼ë¡œ ì¶©ë¶„íˆ í•™ìŠµì„ ì™„ë£Œí•œ ëª¨ë¸
    - ì‚¬ì „ì— í•™ìŠµëœ weight
    - weight ì •í•´ì§„ ëª¨ë¸ì—ë§Œ ì ìš©ëœë‹¤.
        - VGG weightë¥¼ EfficientNetì— ì ìš© ë¶ˆê°€!!
- Transfer Learning (ì „ì´í•™ìŠµ)
    - Pre Trained modelì„ ìƒˆë¡œìš´ Dataset(features, label)ë¡œ ë‹¤ì‹œ í•™ìŠµì‹œí‚¨ë‹¤.
- Fine Tunning (ë¯¸ì„¸ ì¡°ì •)
    - Tranfer Learningê³¼ ë‹¬ë¦¬ Pre Trained model ì¼ë¶€ layerë¥¼ ìˆ˜ì •í•´ ìƒˆë¡œìš´ Dataset(features, label)ë¡œ ë‹¤ì‹œ í•™ìŠµ ì‹œí‚¤ëŠ” ê²ƒ
    - íŠ¹ì • Layerë¥¼ ìˆ˜ì •

### Transfer Learning (ì „ì´í•™ìŠµ) í•˜ëŠ” ì´ìœ 

- ëª¨ë“  ê¸°ì—…ì´ ë§ì€ ë°ì´í„°ë¥¼ ê°€ì§€ê³  ìˆì§€ ì•Šê¸° ë•Œë¬¸ì—
    - ë§ì€ ë°ì´í„°ë¥¼ ê°€ì§€ê³  ìˆëŠ” ê¸°ì—…ì´ Pre Trained model ì„ ì œê³µí•œë‹¤.

![1](../img/img_ft1.png)

### Transfer Learning / Fine tunning ê³ ë¥´ëŠ” ê¸°ì¤€

![2](../img/img_ft2.png)

- ë°•ìŠ¤ : Model
    - ê¸´ ë°•ìŠ¤ : Convolusion + Pooling : features íŠ¹ì§• ìƒì„±
    - ì§§ì€ ë°•ìŠ¤ : Flatten + Linear : í•´ë‹¹ features ê°€ì§€ê³  í•™ìŠµ
- íŒŒë€ìƒ‰ : Fine Tunningì˜ ì •ë„
    - 1 : ì „ì²´ Layerë¥¼ ìˆ˜ì •
    - 4 : ë§ˆì§€ë§‰ë§Œ ìˆ˜ì •
1. ê°€ì§€ê³  ìˆëŠ” Datasetì˜ í¬ê¸°
    1. ë°ì´í„°ì˜ ì–‘ì— ë§ë‹¤. â‡’ 1, 2
    2. ë°ì´í„°ì˜ ì–‘ì´ ì ë‹¤ â‡’ 3, 4
2. Datasetì˜ ë‹¨ìˆœí•œì§€, ë³µì¡í•œì§€
    1. ë°ì´í„°ê°€ ë‹¨ìˆœ â‡’ 2, 4
    2. ë°ì´í„°ê°€ ë³µì¡ â‡’ 1, 3

### Fine Tunning Code (EfficientNet, MobileNet)

1. ëª¨ë“ˆ ì„í¬íŠ¸
    
    ```python
    import os # í™˜ê²½ì„¤ì •
    
    import numpy as np # í–‰ë ¬ ê³„ì‚° ëª¨ë“ˆ
    import torch # pytorch ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ëª¨ë“ˆ
    from torch import nn # ì‹ ê²½ë§ ëª¨ë¸ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ëª¨ë“ˆ
    
    import matplotlib.pyplot as plt # ë°ì´í„° ì‹œê°í™”ê´€ë ¨ ëª¨ë“ˆ
    
    import random # ëœë¤ í•¨ìˆ˜ ì‚¬ìš© ëª¨ë“ˆ
    from PIL import Image # ì´ë¯¸ì§€ ì²˜ë¦¬ë¥¼ ìœ„í•œ ëª¨ë“ˆ
    from pathlib import Path # íŒŒì¼ íŒ¨ìŠ¤ ëª¨ë“ˆ
    
    from torch.utils.data import DataLoader # ë°ì´í„°ë¥¼ batchë‹¨ìœ„ë¡œ ìë¥´ê¸° ìœ„í•œ ëª¨ë“ˆ
    # pytorchì—ì„œ ì‚¬ìš©í•˜ëŠ” ì»´í“¨í„° ë¹„ì „ ì‘ì—…ì„ ìœ„í•œ ëª¨ë“ˆ
    # (ì´ë¯¸ì§€ ë¶„ë¥˜, ë™ì˜ìƒ ì²˜ë¦¬, ë°ì´í„° ì¦ê°•, ë°ì´í„°ë¡œë”©, ê°ì²´ê°ì§€, ì „ì´í•™ìŠµ ë“±)
    import torchvision
    from torchvision import datasets, transforms
    
    # torch ë²„ì • í™•ì¸
    torch.__version__
    ```
    
    ```python
    # í˜„ì¬ ì‚¬ìš©í•˜ê³  ìˆëŠ” í™˜ê²½ í™•ì¸(cpu, gpu)
    device = "cuda" if torch.cuda.is_available() else "cpu"
    device
    ```
    
    ```python
    # torchinfo ì„¤ì¹˜
    # ëª¨ë¸ì˜ êµ¬ì¡° ë° ë§¤ê°œë³€ìˆ˜ ì •ë³´ í™•ì¸ íŒ¨í‚¤ì§€
    !pip install torchinfo
    ```
    
    ```python
    import torchinfo
    
    # summary : pytorch ëª¨ë¸ êµ¬ì¡°, ë ˆì´ì–´, ë§¤ê°œë³€ìˆ˜, ì…ì¶œë ¥ í¬ê¸° ì •ë³´ ì œê³µ
    try:
        from torchinfo import summary
    except:
        print("[INFO] Couldn't find torchinfo... installing it.")
        !pip install -q torchinfo
        from torchinfo import summary
    ```
    
2. Global Variable ì •ì˜
    
    ```python
    import easydict
    args = easydict.EasyDict()
    
    # ì „ì²´ ë°ì´í„° í•™ìŠµ ìˆ˜
    args.NUM_EPOCHS = 30
    # ëª‡ë²ˆ ì‹œë„í• ì§€ ì‹œë„íšŸìˆ˜
    args.NUM_TRIALS = 5
    
    args.BATCH_SIZE = 32
    
    args.EFFICIENTNET_BEST_MODEL = "efficientNet_best_model"
    ```
    
3. ì‚¬ìš©í•  í•¨ìˆ˜ ì •ì˜
    
    ```python
    # SEED ê³ ì • í•¨ìˆ˜
    def reset_seeds(seed=42):
        random.seed(seed)
        os.environ['PYTHONHASHSEED'] = str(seed) # íŒŒì´ì¬ í™˜ê²½ë³€ìˆ˜ ì‹œë“œ ê³ ì •
        np.random.seed(seed)
        torch.manual_seed(seed) # cpu ì—°ì‚° ë¬´ì‘ìœ„ ê³ ì •
        torch.cuda.manual_seed(seed) # gpu ì—°ì‚° ë¬´ì‘ìœ„ ê³ ì •
        torch.backends.cudnn.deterministic = True  # cuda ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ Deterministic(ê²°ì •ë¡ ì )ìœ¼ë¡œ ì˜ˆì¸¡í•˜ê¸° (ì˜ˆì¸¡ì— ëŒ€í•œ ë¶ˆí™•ì‹¤ì„± ì œê±° )
    ```
    
    ```python
    # loss ê·¸ë˜í”„ ê·¸ë¦¬ëŠ” í•¨ìˆ˜
    def plot_loss_curves(results):
        # train / test loss ê°’
        loss = results['train_loss']
        test_loss = results['test_loss']
    
        # train / test acc ê°’
        accuracy = results['train_acc']
        test_accuracy = results['test_acc']
    
        # ì „ì²´ epoch ìˆ˜
        epochs = range(len(results['train_loss']))
    
        # 15, 7 í¬ê¸°ì˜ ë„í™”ì§€ ìƒì„±
        plt.figure(figsize=(15, 7))
    
        plt.subplot(1, 2, 1)
        plt.plot(epochs, loss, label='train_loss')
        plt.plot(epochs, test_loss, label='test_loss')
        plt.title('Loss')
        plt.xlabel('Epochs')
        plt.legend()
    
        plt.subplot(1, 2, 2)
        plt.plot(epochs, accuracy, label='train_accuracy')
        plt.plot(epochs, test_accuracy, label='test_accuracy')
        plt.title('Accuracy')
        plt.xlabel('Epochs')
        plt.legend();
    ```
    
    ```python
    from typing import List, Tuple
    
    # ì´ë¯¸ì§€ ì˜ˆì¸¡ ì ìˆ˜ ì‹œê°í™”
    def pred_and_plot_image(model: torch.nn.Module,
                            image_path: str,
                            class_names: List[str],
                            transform: torchvision.transforms,
                            image_size: Tuple[int, int] = (224, 224),
                            device: torch.device="cpu"):
    
        # ì´ë¯¸ì§€ ì½ì–´ì˜¤ê¸°
        img = Image.open(image_path)
    
        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤í–‰
        # ë§¤ê°œë³€ìˆ˜ë¡œ ë„˜ì–´ì˜¤ transformì´ ìˆì„ ê²½ìš°
        if transform is not None:
            image_transform = transform
        # ë§¤ê°œë³€ìˆ˜ë¡œ ë„˜ì–´ì˜¤ transformì´ ì—†ì„ ê²½ìš°
        else:
            image_transform = transforms.Compose([
                transforms.Resize(image_size),
                transforms.ToTensor()
            ])
    
        ### Predict on image ###
    
        # model í™˜ê²½ í†µì¼
        model.to(device)
    
        # model í‰ê°€ ëª¨ë“œ
        model.eval()
        # model íŒŒë¼ë¯¸í„° ê³ ì •
        with torch.inference_mode():
          # ì´ë¯¸ì§€ ì°¨ì› ëŠ˜ë¦¬ê¸° (modelì—ì„œ ì‚¬ìš©í•œ ê²ƒê³¼ í†µì¼í•´ ì£¼ì–´ì•¼ í•˜ê¸° ë•Œë¬¸ì—)
          transformed_image = image_transform(img).unsqueeze(dim=0)
    
          # ì´ë¯¸ì§€ ì˜ˆì¸¡
          target_image_pred = model(transformed_image.to(device))
    
        # í‰ê°€ ì ìˆ˜ë¥¼ í™•ë¥ ê°’ìœ¼ë¡œ ë³€ê²½
        target_image_pred_probs = torch.softmax(target_image_pred, dim=1)
    
        # ì´ë¯¸ì§€ ì˜ˆì¸¡ ë¼ë²¨ê°’
        target_image_pred_label = torch.argmax(target_image_pred_probs, dim=1)
    
        # ì´ë¯¸ì§€ ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”
        plt.figure()
        plt.imshow(img)
        plt.title(f"Pred: {class_names[target_image_pred_label]} | Prob: {target_image_pred_probs.max():.3f}")
        plt.axis(False);
    ```
    
4. ë°ì´í„° ë¡œë“œ
    
    ```python
    import requests
    import zipfile
    from pathlib import Path
    
    # Setup path to data folder
    data_path = Path("data/")
    image_path = data_path / "pizza_steak_sushi" # data/pizza_steak_sushi
    
    # If the image folder doesn't exist, download it and prepare it...
    if image_path.is_dir():
        print(f"{image_path} directory exists.")
    else:
        print(f"Did not find {image_path} directory, creating one...")
        image_path.mkdir(parents=True, exist_ok=True)
    
        # Download pizza, steak, sushi data
        with open(data_path / "pizza_steak_sushi.zip", "wb") as f:
            request = requests.get("https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip")
            print("Downloading pizza, steak, sushi data...")
            f.write(request.content)
    
        # Unzip pizza, steak, sushi data
        with zipfile.ZipFile(data_path / "pizza_steak_sushi.zip", "r") as zip_ref:
            print("Unzipping pizza, steak, sushi data...")
            zip_ref.extractall(image_path)
    ```
    
    ```python
    # ë°ì´í„°ê°€ ì¡´ì¬í•˜ëŠ” ê²½ë¡œë“¤ í”„ë¦°íŠ¸
    def walk_through_dir(dir_path):
      for dirpath, dirnames, filenames in os.walk(dir_path):
        print(f"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.")
    ```
    
    ```python
    train_dir = image_path / "train"
    test_dir = image_path / "test"
    
    train_dir, test_dir
    ```
    
5. EDA
    1. ë¡œë“œí•œ ë°ì´í„° ì´ë¯¸ì§€ í™•ì¸
    
    ```python
    # Set seed
    reset_seeds() # <- try changing this and see what happens
    
    # ("*/*/*.jpg") : ëª¨ë“  í´ë”ì— ìˆëŠ” jpg ì¡°íšŒ
    # * : train/test í´ë”
    # */* : train/test í´ì–´ ì•ˆì— pizza/steak/sushi í´ë”
    image_path_list = list(image_path.glob("*/*/*.jpg"))
    
    # 2. Get random image path
    # random.choice(sample) : ë¹„ë³µì›
    # random.choices(samples) : ë³µì›
    random_image_path = random.choice(image_path_list)
    
    # Random ì¶”ì¶œëœ jpg íŒŒì¼ì˜ ë¶€ëª¨ í´ë”
    image_class = random_image_path.parent.stem
    
    # Random ì¶”ì¶œëœ jpg íŒŒì¼ open(ì½ê¸°)
    img = Image.open(random_image_path)
    
    # 5. Print metadata
    print(f"Random image path: {random_image_path}")
    print(f"Image class: {image_class}")
    print(f"Image height: {img.height}")
    print(f"Image width: {img.width}")
    print(f"Image type: {type(img)}")
    print(f"Image shape: {img.size}")
    img
    ```
    
    ```python
    # ì‹œê°í™”ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ numpyë¡œ í˜•ë³€í™˜
    img_as_array = np.asarray(img)
    
    # ì´ë¯¸ì§€ ì‹œê°í™”
    plt.figure(figsize=(10, 7))
    plt.imshow(img_as_array)
    plt.title(f"Image class: {image_class} | Image shape: {img_as_array.shape} -> [height, width, color_channels]")
    plt.axis(False);
    ```
    
6. Pre-trained Model augment í™•ì¸
    1. weights ì •ë³´ (transform)
    
    ```python
    # ì‚¬ì „ í•™ìŠµ ëª¨ë¸ ê°€ì ¸ì˜¤ê¸° (EfficientNet_B0_Weights)
    # .DEFAULT = í•´ë‹¹ ëª¨ë¸ ì¤‘ ìµœì í™”ëœ ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°
    weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT
    weights
    ```
    
    ```python
    # ì‚¬ì „ í•™ìŠµ ëª¨ë¸ì˜ transform ì •ë³´
    auto_transforms = weights.transforms()
    auto_transforms
    ```
    
7. Dataset Class ë§Œë“¤ê¸°
    1. Pre-trained Model augment ì ìš©í•œ Dataset Class ë§Œë“¤ê¸°
    
    ```python
    # Dataset ë§Œë“¤ê¸°
    train_dataset = datasets.ImageFolder(train_dir, transform=auto_transforms)
    test_dataset = datasets.ImageFolder(test_dir, transform=auto_transforms)
    
    train_dataset, test_dataset
    ```
    
8. DataLoader
    1. ë°°ì¹˜ ì‚¬ì´ì¦ˆë¡œ ë‚˜ëˆˆ ë°ì´í„°
    
    ```python
    reset_seeds()
    
    # Dataë¥¼ batchë¡œ ë‚˜ëˆˆë‹¤.
    train_dataloader = DataLoader(train_dataset,
                                  batch_size=args.BATCH_SIZE,
                                  shuffle=True)
    
    test_dataloader = DataLoader(test_dataset,
                                 batch_size=args.BATCH_SIZE,
                                 shuffle=False)
    
    train_dataloader, test_dataloader
    ```
    
9. Model
    1. Pre-trained Model ì •ë³´ í™•ì¸ (weights)
        1. Layer ì •ë³´
        2. summary
        
        ```python
        # WeightsEnum : ì‚¬ì „í•™ìŠµ weightsë¥¼ ë‹¤ë£°ë•Œ ì‚¬ìš©
        from torchvision.models._api import WeightsEnum
        # torch.hubì—ì„œ ì‚¬ì „í•™ìŠµ ëª¨ë¸ì„ ê°€ì ¸ì˜¨ë‹¤.
        # load_state_dict_from_url : ëª¨ë¸ì˜ weights ê°€ì ¸ì˜¨ë‹¤.
        from torch.hub import load_state_dict_from_url
        
        def get_state_dict(self, *args, **kwargs):
            kwargs.pop("check_hash")
            return load_state_dict_from_url(self.url, *args, **kwargs)
        
        WeightsEnum.get_state_dict = get_state_dict
        ```
        
        ```python
        # ì‚¬ì „í•™ìŠµ(pre-trained) ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        # classifierë§Œ í™•ì¸í•˜ë©´ë¨
        # ëª¨ë¸ì˜ ê°€ì¥ ë§ˆì§€ë§‰ ë ˆì´ì–´ì˜ outputì€ classì™€ ê°™ë‹¤.
        # ì²«ë²ˆì§¸ ë ˆì´ì–´ì˜ inputê°’ í™•ì¸ => 3 => ì»¬ëŸ¬
        model = torchvision.models.efficientnet_b0(weights=weights).to(device)
        model
        ```
        
        ```python
        summary(model=model,
                input_size=(32, 3, 224, 224),
                # col_names=["input_size"], # uncomment for smaller output
                col_names=["input_size", "output_size", "num_params", "trainable"],
                col_width=20,
                row_settings=["var_names"]
        )
        ```
        
    2. ëª¨ë¸ ìˆ˜ì • (Quadrant 4ì˜ ê²½ìš°)
        1. ë§ˆì§€ë§‰ Layer ìˆ˜ì • (Classifier ìˆ˜ì •)
        
        ```python
        # Sequential (classifier)ë§Œ Falseë¡œ í•´ì„œ í•™ìŠµ ì‹œí‚¨ë‹¤.
        # output_shapeë„ ì»¤ìŠ¤í…€í•œë‹¤.
        # ëª¨ë¸ì˜ featureë§Œ ê³ ì •í•œë‹¤.
        for param in model.features.parameters():
            param.requires_grad = False
        ```
        
        ```python
        reset_seeds()
        
        # ìš°ë¦¬ì˜ ë°ì´í„° output_shapeìœ¼ë¡œ ë§ì¶”ì–´ ì¤€ë‹¤.
        output_shape = len(train_dataset.classes)
        
        # ì‚¬ì „í•™ìŠµ ëª¨ë¸ì—ì„œ classifierë§Œ ìš°ë¦¬ì˜ ë°ì´í„°ì— ë§ê²Œ ìˆ˜ì •í•˜ì—¬ ìƒì„±í•œë‹¤.
        model.classifier = torch.nn.Sequential(
            torch.nn.Dropout(p=0.2, inplace=True),
            torch.nn.Linear(in_features=1280,
                            out_features=output_shape,
                            bias=True)).to(device)
        ```
        
        ```python
        # summary : pytorch ëª¨ë¸ êµ¬ì¡°, ë ˆì´ì–´, ë§¤ê°œë³€ìˆ˜, ì…ì¶œë ¥ í¬ê¸° ì •ë³´ ì œê³µ
        summary(model,
                input_size=(32, 3, 224, 224),
                verbose=0,
                col_names=["input_size", "output_size", "num_params", "trainable"],
                col_width=20,
                row_settings=["var_names"]
        )
        ```
        
10. Engine
    1. loss_fn / optimizer
        
        ```python
        # lossí•¨ìˆ˜ì™€ optimizer(ì—­ì „íŒŒ) ì •ì˜
        loss_fn = nn.CrossEntropyLoss()
        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
        ```
        
    2. train_loop / test_loop
        
        ```python
        def train_step(model: torch.nn.Module,
                       dataloader: torch.utils.data.DataLoader,
                       loss_fn: torch.nn.Module,
                       optimizer: torch.optim.Optimizer):
            # í•™ìŠµ ëª¨ë“œ
            model.train()
        
            # lossì™€ acc ì €ì¥ ë³€ìˆ˜ ì„ ì–¸ ë° ì´ˆê¸°í™”
            train_loss, train_acc = 0, 0
        
            # -> X: features (batch, color, height, width)
            # -> y: target (batch)
            for batch, (X, y) in enumerate(dataloader):
                # í•™ìŠµ ë°ì´í„°ì™€ ëª¨ë¸ì´ ê°™ì€ í™˜ê²½ì— ìˆì–´ì•¼ í•œë‹¤.
                X, y = X.to(device), y.to(device)
        
                # 1. Forward pass
                # ëª¨ë¸ í•™ìŠµ
                y_pred = model(X)
        
                # 2. Calculate  and accumulate loss
                # 2. í•™ìŠµ ê²°ê³¼ì— loss ê°’
                loss = loss_fn(y_pred, y)
                train_loss += loss.item()
        
                # 3. Optimizer zero grad
                # ê¸°ìš¸ê¸° ê³ ì •
                optimizer.zero_grad()
        
                # 4. Loss backward
                # ì—­ì „íŒŒ
                loss.backward()
        
                # 5. Optimizer step
                # ë‹¤ìŒ ë‹¨ê³„ë¡œ ë„˜ê¸´ë‹¤.
                optimizer.step()
        
                # Calculate and accumulate accuracy metric across all batches
                y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)
                train_acc += (y_pred_class == y).sum().item()/len(y_pred)
        
            # Adjust metrics to get average loss and accuracy per batch
            train_loss = train_loss / len(dataloader)
            train_acc = train_acc / len(dataloader)
            return train_loss, train_acc
        ```
        
        ```python
        def test_step(model: torch.nn.Module,
                      dataloader: torch.utils.data.DataLoader,
                      loss_fn: torch.nn.Module):
            # í‰ê°€ ëª¨ë“œ
            model.eval()
        
            # test_loss, test_acc ë³€ìˆ˜ ì„ ì–¸ ë° ì´ˆê¸°í™”
            test_loss, test_acc = 0, 0
        
            # ëª¨ë¸ íŒŒë¼ë¯¸í„° ê³ ì •
            with torch.inference_mode():
                # -> X: features (batch, color, height, width)
                # -> y: target (batch)
                for batch, (X, y) in enumerate(dataloader):
                    # ëª¨ë¸ê³¼ ë™ì¼í•œ í™˜ê²½
                    X, y = X.to(device), y.to(device) # X (), y ()
        
                    # 1. Forward pass
                    test_pred_logits = model(X) # pred ()
        
                    # 2. Calculate and accumulate loss
                    loss = loss_fn(test_pred_logits, y)
                    test_loss += loss.item()
        
                    # Calculate and accumulate accuracy
                    test_pred_labels = test_pred_logits.argmax(dim=1) # pred_labes ()
                    test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))
        
            # Adjust metrics to get average loss and accuracy per batch
            test_loss = test_loss / len(dataloader)
            test_acc = test_acc / len(dataloader)
            return test_loss, test_acc
        ```
        
    3. main (train_loop + test_loop)
        
        ```python
        from tqdm.auto import tqdm
        
        # 1. Take in various parameters required for training and test steps
        def main(model: torch.nn.Module,
                  train_dataloader: torch.utils.data.DataLoader,
                  test_dataloader: torch.utils.data.DataLoader,
                  optimizer: torch.optim.Optimizer,
                  early_stopper,
                  loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),
                  epochs: int = 5):
        
            # 2. Create empty results dictionary
            # ê²°ê³¼ê°’ì„ ë„£ì„ ë¦¬ìŠ¤íŠ¸ ìƒì„±
            results = {"train_loss": [],
                "train_acc": [],
                "test_loss": [],
                "test_acc": []
            }
        
            # 3. Loop through training and testing steps for a number of epochs
            # ì„¤ì •í•œ epoch ë§Œí¼ í•™ìŠµ ë° ì˜ˆì¸¡ ì‹¤í–‰
            for epoch in tqdm(range(epochs)):
                train_loss, train_acc = train_step(model=model,
                                                   dataloader=train_dataloader,
                                                   loss_fn=loss_fn,
                                                   optimizer=optimizer)
                test_loss, test_acc = test_step(model=model,
                                                dataloader=test_dataloader,
                                                loss_fn=loss_fn)
        
                # 4. Print out what's happening
                # ë°°ì¹˜ë‹¨ìœ„ ë‹¹ ê²°ê³¼ ì¶œë ¥
                print(
                    f"Epoch: {epoch+1} | "
                    f"train_loss: {train_loss:.4f} | "
                    f"train_acc: {train_acc:.4f} | "
                    f"test_loss: {test_loss:.4f} | "
                    f"test_acc: {test_acc:.4f}"
                )
        
                # 5. Update results dictionary
                # ë°°ì¹˜ë‹¨ìœ„ ë‹¹ ê²°ê³¼ ì €ì¥
                results["train_loss"].append(train_loss)
                results["train_acc"].append(train_acc)
                results["test_loss"].append(test_loss)
                results["test_acc"].append(test_acc)
        
                # 6. early stopper
                # over fitting ë˜ì§€ ì•Šê²Œ í™•ì¸í•œë‹¤.
                if not early_stopper.is_continuable(model, test_loss):
                    print(f'validation: best loss: {early_stopper.best_loss}')
                    break
        
            # 7. Return the filled results at the end of the epochs
            return results
        ```
        
    4. Early Stopping
        
        ```python
        class EarlyStopper(object):
        
            def __init__(self, num_trials, save_path):
                self.num_trials = num_trials
                self.trial_counter = 0
                self.best_loss = np.inf
                self.save_path = save_path
        
            def is_continuable(self, model, loss):
                if loss < self.best_loss: # í˜„ì¬ lossê°€ ìµœê³  lossë³´ë‹¤ ë” ë‚®ì€ ê²½ìš°
                    self.best_loss = loss # ìµœê³  lossë¥¼ í˜„ì¬ lossë¡œ ì—…ë°ì´íŠ¸
                    self.trial_counter = 0 # ì´ˆê¸°í™”
                    torch.save(model, self.save_path) # ìµœê³  lossë¥¼ ê°–ì€ ëª¨ë¸ ì €ì¥
                    return True
                elif self.trial_counter + 1 < self.num_trials: # í˜„ì¬ lossê°€ ìµœê³  lossë³´ë‹¤ ì‘ì€ ê²½ìš° & max ì‹œë„íšŸìˆ˜ë³´ë‹¤ í˜„ì¬ ì‹œë„íšŸìˆ˜ê°€ ì‘ì€ ê²½ìš°
                    self.trial_counter += 1 # ê¸°ì¡´ ì‹œë„íšŸìˆ˜ + 1
                    return True
                else: # í˜„ì¬ ì •í™•ë„ê°€ ìµœê³  ì •í™•ë„ë³´ë‹¤ ì‘ì€ ê²½ìš° & í˜„ì¬ ì‹œë„íšŸìˆ˜ê°€ max ì‹œë„íšŸìˆ˜ë³´ë‹¤ í° ê²½ìš°
                    return False
        
            def get_best_model(self, device):
                return torch.load(self.save_path).to(device)
        ```
        
11. í•™ìŠµ
    
    ```python
    # Set the random seeds
    reset_seeds()
    
    loss_fn = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)
    
    early_stopper = EarlyStopper(num_trials=args.NUM_TRIALS, save_path=args.EFFICIENTNET_BEST_MODEL)
    
    # ì–¼ë§ˆë‚˜ ì‹œê°„ì´ ê±¸ë¦¬ëŠ”ì§€ í™•ì¸í•˜ê¸° ìœ„í•´ ì‹œê°„ ì¸¡ì •
    # Start the timer
    from timeit import default_timer as timer
    start_time = timer()
    
    # Setup training and save the results
    results = main(model=model,
                   train_dataloader=train_dataloader,
                   test_dataloader=test_dataloader,
                   optimizer=optimizer,
                   early_stopper=early_stopper,
                   loss_fn=loss_fn,
                   epochs=args.NUM_EPOCHS)
    
    # End the timer and print out how long it took
    end_time = timer()
    print(f"[INFO] Total training time: {end_time-start_time:.3f} seconds")
    ```
    
12. loss ë° acc ê°’ ê·¸ë˜í”„ë¡œ í™•ì¸
    
    ```python
    plot_loss_curves(results)
    ```
    
13. Test
    
    ```python
    import random
    num_images_to_plot = 3
    test_image_path_list = list(Path(test_dir).glob("*/*.jpg")) # get list all image paths from test data
    test_image_path_sample = random.sample(population=test_image_path_list, # go through all of the test image paths
                                           k=num_images_to_plot) # randomly select 'k' image paths to pred and plot
    
    # Make predictions on and plot the images
    for image_path in test_image_path_sample:
        pred_and_plot_image(model=model,
                            image_path=image_path,
                            class_names=train_dataset.classes,
                            transform=weights.transforms(), # optionally pass in a specified transform from our pretrained model weights
                            image_size=(224, 224),
                            device=device)
    ```
    
14. Confusion Matrix í™•ì¸
    
    ```python
    from tqdm.auto import tqdm
    
    y_preds = []
    model.eval()
    
    with torch.inference_mode():
      # test ë°ì´í„° í•˜ë‚˜ì”© ê°€ì ¸ì˜¤ê¸° (feature, target)
      for X,y in tqdm(test_dataloader, desc = "Making predictions"):
        # ëª¨ë¸ê³¼ ë™ì¼í•œ í™˜ê²½ ì„¸íŒ…
        X, y = X.to(device), y.to(device)
        # ì˜ˆì¸¡
        y_logit = model(X)
        # ì˜ˆì¸¡ê°’ì„ í™•ë¥ ê°’ìœ¼ë¡œ ë‚˜íƒ€ë‚¸ í›„ ìµœëŒ€ê°’ì˜ ë¼ë²¨ ë°˜í™˜
        y_pred = torch.softmax(y_logit, dim = 1).argmax(dim = 1)
        print(y_pred)
        # ë¼ë²¨ ë¦¬ìŠ¤íŠ¸ì— ê°’ ì €ì¥
        y_preds.append(y_pred.cpu())
      y_pred_tensor = torch.cat(y_preds)
    ```
    
    ```python
    try:
      import torchmetrics, mlxtend
      print(f"mlxtend version: {mlxtend.__version__}")
      assert int(mlxtend.__version__.split(".")[1]) >= 19
    except:
      !pip install -q torchmetrics -U mlxtend
      import torchmetrics, mlxtend
      print(f"mlxtend version: {mlxtend.__version__}")
    ```
    
    ```python
    class_names = train_dataset.classes
    class_names
    ```
    
    ```python
    from torchmetrics import ConfusionMatrix
    from mlxtend.plotting import plot_confusion_matrix
    
    reset_seeds()
    
    confmat = ConfusionMatrix(num_classes=len(class_names), task='multiclass')
    confmat_tensor = confmat(preds=y_pred_tensor,
                            target=torch.tensor(test_dataset.targets))
    
    fig, ax = plot_confusion_matrix(
        conf_mat=confmat_tensor.numpy(), # matplotlib likes working with NumPy
        class_names=class_names, # turn the row and column labels into class names
        figsize=(10, 7)
    );
    ```
    

### MobileNet

- ê³ ì„±ëŠ¥ í™˜ê²½ì´ ì•„ë‹Œ ê³³ì—ì„œ ì‚¬ìš© ê°€ëŠ¥
    - ëª¨ë¸ í•™ìŠµì€ ê³ ì„±ëŠ¥ í™˜ê²½ì—ì„œ í•™ìŠµí•˜ì§€ë§Œ ì‹¤ì œ ì‚¬ìš©í•˜ëŠ” ê³³ì€ ê³ ì„±ëŠ¥ í™˜ê²½ì´ ì•„ë‹ˆê¸°ì—
- ì—°ì‚°ëŸ‰ì´ ì ë‹¤.
- ì ì€ ëª¨ë¸ë¡œ ë†’ì€ ì ìˆ˜
- ë”¥ëŸ¬ë‹ ê²½ëŸ‰í™”
- ìë™ì°¨, ë“œë¡ , ìŠ¤ë§ˆíŠ¸í° ë“±ë“±

![3](../img/img_ft3.png)

<aside>
ğŸ’¡ Reference

</aside>

- ì‚¬ì „ í•™ìŠµ ëª¨ë¸ ì œê³µ ì‚¬ì´íŠ¸
    - https://pytorch.org/vision/stable/models.html#models-and-pre-trained-weights
    - https://pytorch.org/vision/main/models.html
    - https://huggingface.co/models
    - https://github.com/huggingface/pytorch-image-models
    - ë…¼ë¬¸ ê´€ë ¨ ì‚¬ì „ í•™ìŠµ ëª¨ë¸
        - https://paperswithcode.com/
