### 머신러닝 개요
- 딥러닝 < 머신러닝 < 인공지능
- 전통적 프로그래밍 방식
    - 데이터를 보고 사람이 로직을 짜서 컴퓨터가 연산해서 결과를 낸다.
- 머신러닝 프로그래밍 방식
    - 데이터(input, output)를 주고 컴퓨터가 로직을 짜준다.
    - 데이터 사이언티스트 역할
        - 양질의 데이터 준비.
        - 어떤 데이터를 가지고 모델을 학습 했는가 제일 중요.
        - 모델 검증 필요

![1](https://github.com/DaSeul-Seo/Playdata_Study/assets/67898022/0081e764-1a49-4093-a74b-434a4c726aa4)


### 머신러닝 워크플로우

![2](https://github.com/DaSeul-Seo/Playdata_Study/assets/67898022/6ea59aa3-6bfe-4a1c-bc1d-00c6c76e3608)


- 수집
    - input, output 양질의 데이터를 수집
- 점검 및 탐색
    - 내가 필요한 데이터인지 아닌지 판단
    - ex) 한글을 영어로 변환해주는 모델을 만드는데, 일본어와 중국어 등 다른 언어가 들어가 있는지
- 전처리 및 정제
    - 정제 : 쓸모없는 데이터를 제거.
    - 전처리 : 모델이 알맞게 학습할 수 있게 도와주는 추가변수 생성
- 모델링 및 훈련
    - 모델링 : 수많은 모델 중에 하나를 선택해서 파라미터(초기값) 세팅
    - 훈련 : 완성된 데이터들을 통해 학습.
- 평가
    - 학습이 제대로 되었는지 확인
- 배포
    - 평가가 잘 되었으면 사람들이 사용할 수 있게 서비스에 올린다.

### 머신러닝 학습 작동방식

- Loss score를 최소화하는 Parameters를 찾는 과정

![3](https://github.com/DaSeul-Seo/Playdata_Study/assets/67898022/27399744-16ff-49f2-8ed3-12b7b26931d4)


### 머신러닝 모델 종류 (알고리즘 분류)

💡 실습에서는 지도학습을 많이 한다.

- 지도학습
    - input, output 데이터 존재
    - 정답을 이용해 올바르게 학습을 하고 있는지
    - 분류모델 :  나 오늘 점심 뭐 먹을까?, 이건 강아지야 고양이야?
    - 예측(회귀)모델 : 내일 날씨가 맑을 거야, 주식이 오를거야
- 비지도학습
    - input 데이터만 존재
    - 결과를 주지 않는다. (방치)
    - 군집
    - 차원축소
    - 연관규칙
- 강화학습
    - input 데이터만 존재
    - 결과를 알려준다.
    - 틀리면 다시하게 한다.
    - 맞는지 틀린지의 기준이 각각 다르기 때문에 신뢰도가 떨어진다.
    - ex) 게임할 때 맞으면 체력이 줄어든다. → 실수할 때마다 채찍질

![4](https://github.com/DaSeul-Seo/Playdata_Study/assets/67898022/4996317e-1068-4663-82c6-106fc281ffc1)


### 학습용어

- Feature ( = input data)
    - 학습용 데이터
    - 학습하고 싶은 데이터
- Label, Target ( = output data)
    - 우리가 맞추어야 할 결과 데이터
- Class
    - 분류할 때 사용
    - ex) 고양이, 강아지 ⇒ class : 2
    - ex) 황인종, 백인종, 흑인종 ⇒ class : 3
- Parameter
- Hyper parameter
- Loss
- Metric

---

### 머신러닝 실습

- sklearn : 가장 많이 사용하는 것
    - https://scikit-learn.org/stable/
1. 기본 변수 생성
    
    ```python
    # easydict : 변수를 key, value
    import easydict
    args = easydict.EasyDict()
    
    # 실무에서는 random 변수를 많이 사용한다.
    # 그래야 학습이 잘 될 확률이 높아진다.
    # 떄문에 결과값이 매번 달라진다.
    # SEED : random 변수의 값을 고정해준다.
    args.SEED = 10
    args.target_col = 'target'  # target컬럼명을 알려준다.
    ```
    
2. 데이터 수집 (or 데이터 로드)
    1. 이진분류 (binary classification)
    2. ex) 암이 양성인지 음성인지 판단
    3. ex) 강아지인지 고양이인지 판단
    
    ```python
    from sklearn.datasets import load_breast_cancer
    
    # 데이터 로드 => breast_cancer에 담는다.
    breast_cancer = load_breast_cancer()
    # 로드된 데이터 확인
    dir(breast_cancer)
    # 컬럼 확인
    breast_cancer.feature_names
    # target 확인
    breast_cancer.target_names
    ```
    
3. 학습용/검증용 데이터 분리
    
    ```python
    import numpy as np
    import pandas as pd
    
    # sklearn 모듈에서 학습, 검증 데이터를 쪼개는 함수를 쓰겠다.
    from sklearn.model_selection import train_test_split
    
    # 학습용 데이터와 검증용 데이터를 나눈다.
    # DataFrame = 엑셀 표
    # 학습용 데이터
    df_cancer = pd.DataFrame(breast_cancer.data, columns= breast_cancer.feature_names)
    # 검증용 데이터
    df_cancer[args.target_col] = breast_cancer[args.target_col]
    
    print(df_cancer.shape)
    
    # train_test_split
    # random_state = random 상태
    # => 기본으로 항상 random으로 나누어 준다.
    # SEED => random_state 값을 고정해 항상 동일하게 나누게 한다.
    train, test = train_test_split(df_cancer,  random_state=args.SEED)
    
    # 학습, 검증 데이터 상태 확인
    # ((426, 31), (143, 31)) => 컬럼은 동일함
    # 학습 : 426개의 데이터, 컬럼은 31
    # 검증 : 143개의 데이터, 컬럼은 31
    train.shape, test.shape
    ```
    
4. 데이터 점검 및 탐색
    1. test 데이터는 탐색하지 않음
    
    ```python
    train.head()     # 위에 데이터
    train.tail()     # 마지막 데이터
    train.info()     # 데이터 정보 (전체 컬럼, 데이터 형태, 전체 데이터량 등등)
    train.describe() # 통계값 (최소값, 최대값, 평균, 표준편차 등등)
    ```
    
5. 전처리 및 정제
    1. 필요없는 데이터 제거
    
    ![5](https://github.com/DaSeul-Seo/Playdata_Study/assets/67898022/952ac4f1-6a84-48e6-b295-bd93a07311c5)

    
    ```python
    # drop : 로우를 삭제할 것인지, 컬럼을 삭제할 것인지
    # axis : 축 / 0 = 로우축, 1 = 컬럼축
    # feature (학습 / 정답)
    x_train, x_test = train.drop(args.target_col, axis=1), test.drop(args.target_col, axis=1)
    # target (학습 / 정답)
    y_train, y_test = train[args.target_col], test[args.target_col]
    
    # ((426, 30), (426,)) => 컬럼이 1이면 아무것도 안쓰여진다.
    x_train.shape, y_train.shape
    # ((143, 30), (143,))
    x_test.shape, y_test.shape
    ```
    
    ```python
    from sklearn.preprocessing import StandardScaler
    
    # standardization
    # 전처리 작업
    # 각 컬럼의 기준이 다르다.  ex) 연봉 1000, 몸무게 500 크고 작은 것 기준을 세원준다.
    scaler = StandardScaler()
    train_scaled = scaler.fit_transform(x_train)
    test_scaled = scaler.transform(x_test)
    
    print(f'train.shape: {train.shape}')
    print('-'*50)
    print(f'train_scaled.shape: {train_scaled.shape}')
    
    train_scaled[:1,:]
    '''
    array([[-0.60408221, -0.30624914, -0.66228757, -0.59759609, -1.43340425,
            -1.28487074, -1.11254551, -1.12909991, -1.61436823, -0.31081757,
            -0.62155456, -0.5783191 , -0.6928    , -0.50501258, -0.76703944,
            -1.07161825, -1.2493379 , -1.30374665, -0.74688387, -0.81051627,
            -0.67577053, -0.55621057, -0.74396171, -0.63568485, -1.45739321,
            -1.18985953, -1.29522303, -1.34634798, -1.23731664, -0.76362748]])
    '''
    ```
    
6. 모델링 및 훈련
    1. 기본적으로 모델은 클래스이다.
    
    ```python
    # LogisticRegression => 회귀이지만 이진분류가 가능하다.
    from sklearn.linear_model import LogisticRegression
    
    # logistic regression
    lr_clf = LogisticRegression()
    
    # 훈련
    # fit : 학습
    # 학습용 Feature, 학습용 target
    lr_clf.fit(x_train, y_train)
    ```
    
7. 평가
    
    ```python
    from sklearn.metrics import accuracy_score
    
    # 예측
    # predict : 예측, 검증
    pred = lr_clf.predict(x_test)
    
    # 정확도 측정
    # 검증용 target
    accuracy_score(y_test, pred)
    ```
